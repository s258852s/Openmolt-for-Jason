#!/usr/bin/env python3
"""
Hybrid Search - å¤šä¾†æºå”ä½œæœå°‹
æ•´åˆ Google (Serper.dev) + Grok (Web + X) é€²è¡Œäº¤å‰é©—è­‰

Usage: python3 hybrid_search.py "search query" [options]
"""

import argparse
import json
import os
import sys
import concurrent.futures
from datetime import datetime

# Import local search modules
script_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, script_dir)

from google_search import google_search
from grok_search import grok_search

def hybrid_search(query: str, sources: list = None, timeout: int = 60) -> dict:
    """
    Perform hybrid search across multiple sources
    
    Args:
        query: Search query string
        sources: List of sources to use ["google", "grok_web", "grok_x"]
                 Default: all sources
        timeout: Timeout in seconds for each source
    
    Returns:
        dict with combined search results
    """
    if sources is None:
        sources = ["google", "grok_web", "grok_x"]
    
    results = {
        "query": query,
        "timestamp": datetime.now().isoformat(),
        "sources_requested": sources,
        "sources_succeeded": [],
        "sources_failed": [],
        "google": None,
        "grok_web": None,
        "grok_x": None,
        "summary": ""
    }
    
    # Define search tasks
    tasks = {}
    if "google" in sources:
        tasks["google"] = lambda: google_search(query)
    if "grok_web" in sources:
        tasks["grok_web"] = lambda: grok_search(query, mode="web")
    if "grok_x" in sources:
        tasks["grok_x"] = lambda: grok_search(query, mode="x")
    
    # Execute searches concurrently
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        future_to_source = {
            executor.submit(task): source 
            for source, task in tasks.items()
        }
        
        for future in concurrent.futures.as_completed(future_to_source, timeout=timeout):
            source = future_to_source[future]
            try:
                result = future.result()
                if "error" not in result:
                    results[source] = result
                    results["sources_succeeded"].append(source)
                else:
                    results["sources_failed"].append({
                        "source": source,
                        "error": result["error"]
                    })
            except Exception as e:
                results["sources_failed"].append({
                    "source": source,
                    "error": str(e)
                })
    
    # Generate summary
    results["summary"] = generate_summary(results)
    
    return results

def generate_summary(results: dict) -> str:
    """Generate a combined summary from all sources"""
    
    summary_parts = []
    
    # Google results summary
    if results.get("google") and results["google"].get("results"):
        google_res = results["google"]
        summary_parts.append("ã€Google æœå°‹ã€‘")
        
        if google_res.get("answer_box"):
            summary_parts.append(f"ç²¾é¸ç­”æ¡ˆï¼š{google_res['answer_box'].get('answer', '')}")
        
        top_results = google_res["results"][:3]
        for r in top_results:
            summary_parts.append(f"â€¢ {r['title']}")
            if r.get('snippet'):
                summary_parts.append(f"  {r['snippet'][:100]}...")
    
    # Grok Web summary
    if results.get("grok_web") and results["grok_web"].get("content"):
        summary_parts.append("\nã€Grok Web åˆ†æã€‘")
        content = results["grok_web"]["content"]
        # Take first 500 chars of Grok response
        summary_parts.append(content[:500] + "..." if len(content) > 500 else content)
    
    # Grok X summary
    if results.get("grok_x") and results["grok_x"].get("content"):
        summary_parts.append("\nã€X/Twitter å³æ™‚ã€‘")
        content = results["grok_x"]["content"]
        summary_parts.append(content[:500] + "..." if len(content) > 500 else content)
    
    if not summary_parts:
        return "ç„¡æ³•å–å¾—ä»»ä½•æœå°‹çµæœ"
    
    return "\n".join(summary_parts)

def print_results(results: dict):
    """Pretty print search results"""
    
    print(f"\n{'='*60}")
    print(f"ğŸ” æ··åˆæœå°‹çµæœï¼š{results['query']}")
    print(f"â° æ™‚é–“ï¼š{results['timestamp']}")
    print(f"âœ… æˆåŠŸä¾†æºï¼š{', '.join(results['sources_succeeded']) or 'ç„¡'}")
    if results['sources_failed']:
        failed = [f"{f['source']}" for f in results['sources_failed']]
        print(f"âŒ å¤±æ•—ä¾†æºï¼š{', '.join(failed)}")
    print(f"{'='*60}\n")
    
    # Print summary
    print("ğŸ“‹ ç¶œåˆæ‘˜è¦ï¼š")
    print("-" * 40)
    print(results['summary'])
    print()
    
    # Print detailed Google results
    if results.get("google"):
        google = results["google"]
        print("\nğŸŒ Google è©³ç´°çµæœï¼š")
        print("-" * 40)
        for i, r in enumerate(google.get("results", [])[:5], 1):
            print(f"{i}. {r['title']}")
            print(f"   ğŸ”— {r['url']}")
            if r.get('date'):
                print(f"   ğŸ“… {r['date']}")
            print()
    
    # Print Grok citations if available
    if results.get("grok_web") and results["grok_web"].get("citations"):
        print("\nğŸ“š Grok Web å¼•ç”¨ä¾†æºï¼š")
        print("-" * 40)
        for cite in results["grok_web"]["citations"][:5]:
            if isinstance(cite, dict):
                print(f"â€¢ {cite.get('title', '')} - {cite.get('url', '')}")
            else:
                print(f"â€¢ {cite}")
    
    # Print errors if any
    if results['sources_failed']:
        print("\nâš ï¸ éŒ¯èª¤è¨Šæ¯ï¼š")
        print("-" * 40)
        for fail in results['sources_failed']:
            print(f"â€¢ {fail['source']}: {fail['error']}")

def main():
    parser = argparse.ArgumentParser(
        description="Hybrid Search - å¤šä¾†æºå”ä½œæœå°‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹ï¼š
  python3 hybrid_search.py "å°ç£ä»Šæ—¥æ–°è"
  python3 hybrid_search.py "BTC åƒ¹æ ¼" --sources google grok_web
  python3 hybrid_search.py "å·æ™®" --sources grok_x --json
        """
    )
    parser.add_argument("query", help="æœå°‹é—œéµå­—")
    parser.add_argument("--sources", nargs="+", 
                        choices=["google", "grok_web", "grok_x"],
                        default=["google", "grok_web", "grok_x"],
                        help="é¸æ“‡æœå°‹ä¾†æº (é è¨­: å…¨éƒ¨)")
    parser.add_argument("--timeout", type=int, default=60,
                        help="æ¯å€‹ä¾†æºçš„è¶…æ™‚ç§’æ•¸ (é è¨­: 60)")
    parser.add_argument("--json", action="store_true", 
                        help="è¼¸å‡º JSON æ ¼å¼")
    
    args = parser.parse_args()
    
    # Check for API keys
    missing_keys = []
    if "google" in args.sources and not os.environ.get("SERPER_API_KEY"):
        missing_keys.append("SERPER_API_KEY")
    if ("grok_web" in args.sources or "grok_x" in args.sources) and not os.environ.get("XAI_API_KEY"):
        missing_keys.append("XAI_API_KEY")
    
    if missing_keys:
        print(f"âš ï¸ ç¼ºå°‘ API Key: {', '.join(missing_keys)}")
        print("è«‹è¨­å®šç’°å¢ƒè®Šæ•¸æˆ–åŠ å…¥ ~/.clawdbot/clawdbot.json")
        print("\nç¯„ä¾‹ï¼š")
        print('  export SERPER_API_KEY="your_key"')
        print('  export XAI_API_KEY="your_key"')
        sys.exit(1)
    
    # Perform search
    results = hybrid_search(args.query, args.sources, args.timeout)
    
    if args.json:
        print(json.dumps(results, ensure_ascii=False, indent=2))
    else:
        print_results(results)

if __name__ == "__main__":
    main()
